{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9ba1683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random, torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e598cdc",
   "metadata": {},
   "source": [
    "# Vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd88c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL      = [\"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "BASE_CHARS   = list(\"0123456789+= \")\n",
    "VOCAB        = SPECIAL + BASE_CHARS\n",
    "PAD, BOS, EOS = SPECIAL\n",
    "char2idx     = {ch: i for i, ch in enumerate(VOCAB)}\n",
    "idx2char     = {i: ch for ch, i in char2idx.items()}\n",
    "VOCAB_SIZE   = len(VOCAB)\n",
    "\n",
    "INPUT_LEN  = 9                   # «99 + 99 » = 9 car\n",
    "MAX_LEN = INPUT_LEN + 2          # 9 + 2 = 11\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921ebce",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a6575c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_EXPR = \"2 + 2\"                         # 7 caractères (inclut espaces)\n",
    "def tokens_to_str(tokens):\n",
    "    return ''.join(idx2char[t] for t in tokens).rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "335ed9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSeqEnv:\n",
    "    def __init__(self, max_len=MAX_LEN):\n",
    "        self.max_len = max_len\n",
    "    def reset(self):\n",
    "        self.state = [char2idx[BOS]]\n",
    "        return self.state\n",
    "    def step(self, action):\n",
    "        self.state.append(action)\n",
    "        done = (action == char2idx[EOS])\n",
    "\n",
    "        # Abort si longueur dépasse la borne\n",
    "        if not done and len(self.state) >= self.max_len:\n",
    "            return self.state, 0.01, True\n",
    "\n",
    "        if done:\n",
    "            expr = tokens_to_str(self.state[1:-1])   # sans BOS/EOS\n",
    "            reward = 1.0 if expr == TARGET_EXPR else 0.01\n",
    "            return self.state, reward, True\n",
    "\n",
    "        return self.state, 0.0, False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d732f29",
   "metadata": {},
   "source": [
    "# Flow Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "128892b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Policy réseau = log-flux Fθ(s,a)\n",
    "class FlowNet(nn.Module):\n",
    "    def __init__(self, d_model=128, n_heads=4, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(VOCAB_SIZE, d_model, padding_idx=char2idx[PAD])\n",
    "        self.pos = nn.Embedding(MAX_LEN + 1, d_model)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model, n_heads, dropout=0.1, batch_first=True\n",
    "        )\n",
    "        self.tr = nn.TransformerEncoder(enc_layer, n_layers)\n",
    "\n",
    "        self.fc = nn.Linear(d_model, VOCAB_SIZE)\n",
    "        self.fc.weight = self.emb.weight          # weight tying\n",
    "        self.logZ = nn.Parameter(torch.zeros(()))\n",
    "\n",
    "    @staticmethod\n",
    "    def causal_mask(sz, device):\n",
    "        # shape (sz, sz) : True au-dessus de la diagonale\n",
    "        return torch.triu(torch.full((sz, sz), float('-inf'), device=device), 1)\n",
    "\n",
    "    def forward(self, prefix):\n",
    "        \"\"\"\n",
    "        prefix : (B, L)  – renvoie log p(a | s) pour chaque token du vocab.\n",
    "        \"\"\"\n",
    "        B, L = prefix.shape\n",
    "        pos = torch.arange(L, device=prefix.device).unsqueeze(0)\n",
    "        x = self.emb(prefix) + self.pos(pos)\n",
    "\n",
    "        mask = self.causal_mask(L, prefix.device)\n",
    "        x = self.tr(x, mask=mask)                # (B, L, d_model)\n",
    "\n",
    "        logits = self.fc(x)                      # (B, L, V)\n",
    "        return torch.log_softmax(logits[:, -1], -1)  # proba du prochain token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4eac4413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Trajectory Balance loss (corrigé)\n",
    "def tb_loss(model, trajectories, rewards):\n",
    "    losses = []\n",
    "    for tokens, R in zip(trajectories, rewards):\n",
    "        logfwd = 0.0\n",
    "        # parcours des transitions s_k -> a_k (= tokens[k+1])\n",
    "        for k in range(len(tokens) - 1):\n",
    "            prefix = torch.tensor([tokens[:k+1]], device=DEVICE)  # s_k\n",
    "            logp   = model(prefix)                                # log π(a|s)\n",
    "            logfwd = logfwd + logp[0, tokens[k+1]]\n",
    "        logbwd = 0.0        # backward uniform (placeholder)\n",
    "        TB = logfwd + model.logZ - math.log(R) - logbwd\n",
    "        losses.append(TB**2)\n",
    "    return torch.stack(losses).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbd54539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_trajectory(model, env):\n",
    "    state = env.reset()\n",
    "    done  = False\n",
    "    while not done:\n",
    "        prefix = torch.tensor([state], device=DEVICE)\n",
    "        logp   = model(prefix)               # (1, V)\n",
    "        # Catégoriel => choix\n",
    "        action = torch.distributions.Categorical(logits=logp).sample().item()\n",
    "        state, reward, done = env.step(action)\n",
    "    return state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91623852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_flow(model, steps=2, batch_size=32):\n",
    "    env     = AddSeqEnv()\n",
    "    opt     = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "    for step in range(1, steps+1):\n",
    "        trajs, rewards = [], []\n",
    "        for _ in range(batch_size):\n",
    "            t, r = sample_trajectory(model, env)\n",
    "            trajs.append(t); rewards.append(r)\n",
    "        loss = tb_loss(model, trajs, rewards)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "        if step % 1 == 0:\n",
    "            print(f\"[{step:05d}] loss={loss.item():.4f}  logZ={model.logZ.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51464ba",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee72a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, start=\"<bos>\", max_len=MAX_LEN):\n",
    "    model.eval()\n",
    "    ids = [char2idx[start]] if start != \"<bos>\" else [char2idx[BOS]]\n",
    "    for _ in range(max_len):\n",
    "        prefix = torch.tensor([ids], device=DEVICE)\n",
    "        logp   = model(prefix)\n",
    "        tok    = int(logp.argmax(-1))\n",
    "        ids.append(tok)\n",
    "        if tok == char2idx[EOS]:\n",
    "            break\n",
    "    return ''.join(idx2char[i] for i in ids[1:-1])   # sans BOS/EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81b64307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement...\n",
      "[00001] loss=21.2071  logZ=-0.00\n",
      "[00002] loss=20.2666  logZ=-0.00\n",
      "[00003] loss=21.2019  logZ=-0.00\n",
      ">> <bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos>\n",
      ">> <bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos>\n",
      ">> <bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos>\n",
      ">> <bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos>\n",
      ">> <bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos><bos>\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = FlowNet().to(DEVICE)\n",
    "print(\"Entraînement...\")\n",
    "train_flow(model, steps=3, batch_size=64)   # test rapide\n",
    "\n",
    "for _ in range(5):\n",
    "    print(\">>\", generate(model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
